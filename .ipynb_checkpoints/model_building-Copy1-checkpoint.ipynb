{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "#import matplotlib.pyplot as plt\n",
    "    #import re\n",
    "    #import string\n",
    "    #import nltk\n",
    "    #from nltk.stem import SnowballStemmer\n",
    "    #from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "    #from sklearn.model_selection import train_test_split\n",
    "    #import os\n",
    "    #from textblob import TextBlob\n",
    "    #from nltk.stem import PorterStemmer\n",
    "    #from textblob import Word\n",
    "    #from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "    #import sklearn.feature_extraction.text as text\n",
    "    #from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "    #import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>capitals</th>\n",
       "      <th>caps_vs_length</th>\n",
       "      <th>num_exclamation_marks</th>\n",
       "      <th>num_punctuation</th>\n",
       "      <th>num_smilies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>It's Tim Ferriss.  Extracting value that you a...</td>\n",
       "      <td>122</td>\n",
       "      <td>6</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tim Ferriss  a rapidly evolving meta human/mut...</td>\n",
       "      <td>398</td>\n",
       "      <td>14</td>\n",
       "      <td>0.035176</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Anything Tim Ferriss I will buy. Podcasts are ...</td>\n",
       "      <td>177</td>\n",
       "      <td>6</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Awesome and practical!</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>What an incredible book!</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  length  capitals  \\\n",
       "0     0  It's Tim Ferriss.  Extracting value that you a...     122         6   \n",
       "2     0  Tim Ferriss  a rapidly evolving meta human/mut...     398        14   \n",
       "3     0  Anything Tim Ferriss I will buy. Podcasts are ...     177         6   \n",
       "5     0                             Awesome and practical!      22         1   \n",
       "6     0                           What an incredible book!      24         1   \n",
       "\n",
       "   caps_vs_length  num_exclamation_marks  num_punctuation  num_smilies  \n",
       "0        0.049180                      0                4            0  \n",
       "2        0.035176                      0                9            0  \n",
       "3        0.033898                      0                4            0  \n",
       "5        0.045455                      1                0            0  \n",
       "6        0.041667                      1                0            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['label']=df['label'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's Tim Ferriss.  Extracting value that you and I never could.  Worth its weight in gold, and that's a pretty heavy book.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [df.iloc[0,1],df.iloc[1,1],df.iloc[2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It's Tim Ferriss.  Extracting value that you and I never could.  Worth its weight in gold, and that's a pretty heavy book.\",\n",
       " 'Tim Ferriss  a rapidly evolving meta human/mutant/author, etc., who positions and arms himself artfully in the hunt for exquisite perspective and enlightenment  has had his own brilliant mind blown time and again. Thankfully, he has scratched his own itch by compiling some of his field notes. And holy moly. What a prize to share.With Gratitude,Amy of Tools of Titans Charlotte Metro + Lake Norman',\n",
       " 'Anything Tim Ferriss I will buy. Podcasts are awesome and this book distills a ton of information.If you dig this book you absolutely must subscribe to his podcast immediately..']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vectorizer.fit(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vectorizer.transform(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('never')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = stopwords.words(\"english\")\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test, y, y_test = train_test_split(df.loc[:, df.columns != 'label'],df.label,test_size=0.2,train_size=0.8)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y,test_size = 0.25,train_size =0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardization with  sklearn\n",
    "\n",
    "\n",
    "# copy of datasets\n",
    "x_train_stand = x_train.copy()\n",
    "x_test_stand = x_test.copy()\n",
    "x_val_stand = x_val.copy()\n",
    "\n",
    "# numerical features\n",
    "num_cols = ['length', 'capitals','caps_vs_length','num_exclamation_marks','num_punctuation','num_smilies']\n",
    "\n",
    "# apply standardization on numerical features\n",
    "for i in num_cols:\n",
    "    \n",
    "    # fit on training data column\n",
    "    scale = StandardScaler().fit(x_train_stand[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    x_train_stand[i] = scale.transform(x_train_stand[[i]])\n",
    "    \n",
    "    # transform the testing data column\n",
    "    x_test_stand[i] = scale.transform(x_test_stand[[i]])\n",
    "    \n",
    "    x_val_stand[i] = scale.transform(x_val_stand[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([\n",
    "    (['length', 'capitals','caps_vs_length','num_exclamation_marks','num_punctuation','num_smilies'], None),\n",
    "    ('text',TfidfVectorizer(stop_words='english', max_df=0.7))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrameMapper(drop_cols=[],\n",
       "                features=[(['length', 'capitals', 'caps_vs_length',\n",
       "                            'num_exclamation_marks', 'num_punctuation',\n",
       "                            'num_smilies'],\n",
       "                           None),\n",
       "                          ('text',\n",
       "                           TfidfVectorizer(max_df=0.7, stop_words='english'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper.fit(x_train_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_trans = mapper.transform(x_train_stand)\n",
    "xval_trans = mapper.transform(x_val_stand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35829, 19707), (11943, 19707))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_trans.shape,xval_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "#model = linear_model.LogisticRegression().fit(xtrain_trans, y_train)\n",
    "#print(metrics.classification_report(y_val, model.predict(xval_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_3 = SVC(kernel='linear', \n",
    "            class_weight='balanced', # penalize\n",
    "            probability=True)\n",
    "model = clf_3.fit(xtrain_trans, y_train)\n",
    "print(metrics.classification_report(y_val, model.predict(xval_trans)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
